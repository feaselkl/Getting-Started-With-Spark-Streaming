cd /root/dotnet/SparkStreamingDotNetExample/SparkStreamingDotNetExample/

dotnet restore --packages ./packages

dotnet build --configuration Release

# Uncomment the one you want to run.
# For the first two readers, we will need to run nc on port 9999 in another window.
#    Do this with the command:  nc -kl 9999
#    For a longer input, run the following command:  nc -kl 9999 < /root/data/WarAndPeace.txt
# For the Kafka reader, change the IP address to whichever host & port is running Kafka and the topic you'd like to consume.
#    Note that you may see issues running between Docker networks if you use internal Docker IPs.
#    Also note that the Kafka reader requires an extra package be loaded.

#spark-submit \
#	--class org.apache.spark.deploy.dotnet.DotnetRunner \
#	--master local \
#	packages/microsoft.spark/0.12.1/jars/microsoft-spark-2.4.x-0.12.1.jar \
#	dotnet run StructuredStreaming.Repeater

#spark-submit \
#	--class org.apache.spark.deploy.dotnet.DotnetRunner \
#	--master local \
#	packages/microsoft.spark/0.12.1/jars/microsoft-spark-2.4.x-0.12.1.jar \
#	dotnet run StructuredStreaming.WindowedWordCount 15 5
	
#spark-submit \
#	--class org.apache.spark.deploy.dotnet.DotnetRunner \
#	--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.5 \
#	--master local \
#	packages/microsoft.spark/0.12.1/jars/microsoft-spark-2.4.x-0.12.1.jar \
#	dotnet run StructuredStreaming.KafkaReader 192.168.100.120:9092 Flights